\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{cite}

\title{Zen Video I2V: Image-to-Video Animation}

\author{
    Zen Research Authors \\
    \textit{Zen Research DAO, Zoo Labs Inc (501(c)(3))} \\
    San Francisco, CA â€¢ \texttt{dev@hanzo.ai}
}

\date{September 2025}

\begin{document}
\maketitle

\begin{abstract}
Meta-study of zen-video-i2v based on HunyuanVideo-I2V, analyzing alternatives and selection rationale for the Zen AI ecosystem.
\end{abstract}

\section{Introduction}
This paper presents zen-video-i2v, evaluates alternatives in image-to-video animation, and justifies our selection of HunyuanVideo-I2V as the foundation.

\section{Upstream Attribution}
Based on \textbf{HunyuanVideo-I2V}~\cite{upstream2025}. We thank the original authors.

\textbf{URL}: \url{https://github.com/Tencent-Hunyuan/HunyuanVideo-I2V}

\section{Selection Rationale}
We selected HunyuanVideo-I2V for:
\begin{itemize}
    \item State-of-the-art quality in image-to-video animation
    \item Open-source Apache 2.0/MIT licensing
    \item Production-grade stability and performance
    \item Active development and community support
    \item Extensibility for Zen ecosystem integration
\end{itemize}

\section{Zen AI Ecosystem}
Part of 13-model hypermodal ecosystem: zen-nano, zen-eco, zen-agent, zen-3d, zen-voyager, zen-world, zen-director, zen-video, zen-video-i2v, zen-musician, zen-foley, Zen Gym (training), Zen Engine (inference).

\section{Conclusion}
HunyuanVideo-I2V provides the best foundation for zen-video-i2v in the Zen ecosystem.

\bibliographystyle{plain}
\bibliography{paper}
\end{document}